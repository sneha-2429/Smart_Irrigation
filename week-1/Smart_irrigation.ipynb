{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmzieuA2nBuH"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset (update the filename accordingly)\n",
        "df = pd.read_csv(\"irrigation_machine.csv\")\n",
        "\n",
        "# Display first 5 rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display DataFrame information\n",
        "print(\"\\nDataFrame Information:\")\n",
        "df.info()\n",
        "\n",
        "# Display column names\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Drop 'Unnamed: 0' column if it exists\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "print(\"\\nDataFrame after dropping 'Unnamed: 0' column:\")\n",
        "print(df.head())\n",
        "\n",
        "# Display descriptive statistics\n",
        "print(\"\\nDescriptive Statistics of the dataset:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Features (sensor readings)\n",
        "X = df[[f'sensor_{i}' for i in range(20)]]\n",
        "\n",
        "# Target variables (parcel irrigation status)\n",
        "y = df[['parcel_0', 'parcel_1', 'parcel_2']]\n",
        "\n",
        "print(f\"\\nShape of features (X): {X.shape}\")\n",
        "print(f\"Shape of target variables (y): {y.shape}\")\n",
        "\n",
        "# --- Data Visualization ---\n",
        "\n",
        "# Data Visualization: Bar graphs for target variables\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(x='parcel_0', data=df)\n",
        "plt.title('Distribution of Parcel 0 Irrigation Status')\n",
        "plt.xlabel('Parcel 0 Status')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.countplot(x='parcel_1', data=df)\n",
        "plt.title('Distribution of Parcel 1 Irrigation Status')\n",
        "plt.xlabel('Parcel 1 Status')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.countplot(x='parcel_2', data=df)\n",
        "plt.title('Distribution of Parcel 2 Irrigation Status')\n",
        "plt.xlabel('Parcel 2 Status')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Data Visualization: Sensor Data Distributions (Histograms/KDE)\n",
        "print(\"\\n--- Sensor Data Distributions ---\")\n",
        "num_sensors = X.shape[1]\n",
        "# Determine grid size for subplots\n",
        "cols = 4\n",
        "rows = (num_sensors + cols - 1) // cols # Ceiling division\n",
        "plt.figure(figsize=(cols * 4, rows * 3))\n",
        "for i, col in enumerate(X.columns):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    sns.histplot(X[col], kde=True)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Data Visualization: Correlation Heatmap\n",
        "plt.figure(figsize=(18, 15))\n",
        "# Combine features and targets for correlation analysis\n",
        "correlation_data = pd.concat([X, y], axis=1)\n",
        "sns.heatmap(correlation_data.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Matrix of Sensor Readings and Parcel Status')\n",
        "plt.show()\n",
        "\n",
        "# --- Machine Learning Model ---\n",
        "\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit and transform the features\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert scaled features back to DataFrame (optional, but good for consistency)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the MultiOutputClassifier with RandomForestClassifier\n",
        "multi_output_model = MultiOutputClassifier(estimator=RandomForestClassifier(random_state=42))\n",
        "multi_output_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = multi_output_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model for each output\n",
        "print(\"\\n--- Model Evaluation ---\")\n",
        "for i, parcel_col in enumerate(y.columns):\n",
        "    print(f\"Classification Report for {parcel_col}:\\n\")\n",
        "    print(classification_report(y_test[parcel_col], y_pred[:, i]))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# --- Feature Importance Plots for Each Parcel ---\n",
        "print(\"\\n--- Feature Importance Plots ---\")\n",
        "plt.figure(figsize=(18, 6))\n",
        "for i, parcel_col in enumerate(y.columns):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    # Get feature importances from the estimator for the current output\n",
        "    importances = multi_output_model.estimators_[i].feature_importances_\n",
        "    features_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
        "    features_df = features_df.sort_values(by='Importance', ascending=False)\n",
        "    sns.barplot(x='Importance', y='Feature', data=features_df.head(10)) # Top 10 features\n",
        "    plt.title(f'Feature Importance for {parcel_col}')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.ylabel('Sensor Feature')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model and scaler\n",
        "joblib.dump(multi_output_model, 'multi_output_irrigation_model.joblib')\n",
        "joblib.dump(scaler, 'min_max_scaler.joblib')\n",
        "\n",
        "print(\"\\nModel and scaler saved successfully.\")"
      ]
    }
  ]
}